---
title: "Activity 1"
author: "Brooke Wolford"
date: "2025-12-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Actvitiy 1

Objective: Use information from Module 1 to read in sensitive data and filter to relevant variables

### Pair programming

Pair programming is a technique where two programmers work together at one workstation. One programmer, the driver, writes the code, while the other, the navigator, reviews the code as it's being written and offers suggestions. The goal is to learn from each other. It's best practice to switch driver and navigator roles roughly every 10 minutes or whenever you come to a natural break point.

### Set up environment


```{r}

#install.packages("haven")
library(haven)
library(tidyr)
library(dplyr)
library(readr)
library(ggplot2)
library(skimr)

sessionInfo()

```

### Reading in the data

We are reading in data from the National Health and Nutrition Examination Survey from August 2021-August 2023. The complete set of data is available [here](https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Questionnaire&Cycle=2021-2023).

These are in a .xpt format which is a SAS Transport file format for data sharing and can be read into R with the `haven` package.

The documentation for the files can be found here:
[diabetes](https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DIQ_L.htm)
[physical activity](https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/PAQ_L.htm)
[weight](https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/WHQ_L.htm)

The join functions are important within dplyr. You can read more [here](https://dplyr.tidyverse.org/reference/mutate-joins.html).

This data could be used to ask a lot of questions. Take time to look into the documentation about the variables. What kind of hypotheses do you have based on what you have seen so far? Think about what you might like to research using AI methods. We will continue with this dataset in the next two activities.

```{r}
#diabetes
dia<-read_xpt("data/DIQ_L.xpt")

#physical activity
pa<-read_xpt("data/PAQ_L.xpt")

#weight
wei<-read_xpt("data/WHQ_L.xpt")

#diabetes data has more samples than physical activity and weight, so let's do a left join with physicial activity as the anchoring file
df<-left_join(pa,dia) %>% left_join(wei)


```

We now have a dataset with 8153 participants and 20 columns.

### Sensitive Data

Researchers must adhere to national and international regulations, such as the General Data Protection Regulation (GDPR) in the European Union or the Health Insurance Portability and Accountability Act (HIPAA) in the United States. These frameworks define how sensitive data can be collected, stored, shared, and used. For example, under GDPR, data must be processed lawfully, transparently, and only for specified purposes. Researchers are also required to implement data minimization and to ensure that data are accurate, kept up to date, and stored securely.

In practice, ethical research with sensitive data involves several layers of protection. First, researchers typically seek approval from an ethics committee or institutional review board (IRB), which assesses the risks and benefits of the study and ensures that informed consent is obtained. Consent forms should clearly explain how the data will be used, who will have access, and what measures are in place to protect confidentiality. In some cases, broad consent may be used for biobanks or longitudinal studies, but this must still respect participantsâ€™ autonomy and rights.

To further protect individuals, sensitive data are often de-identified or pseudonymized, meaning that direct identifiers are removed or replaced with codes. However, even de-identified data can carry risks of re-identification, particularly when linked with other datasets. As a result, researchers must employ technical safeguards (such as encryption and secure servers) as well as administrative controls (like restricted access and data-use agreements) to mitigate these risks.

Ultimately, the responsible use of sensitive data is essential for building public trust and ensuring the long-term sustainability of biomedical research.

### Tidying the data

```{r}

#use glimpse() to try to understand the data 


#let's make a variable for current BMI using the mutate function
#BMI=weight in lbs * 703/height in inches squared


#use skim to look at the variables


#let's use mutate to rename the variables to more comprehensible names


#check the names of the dataframe


#let's subset to just these renamed variables and BMI


#let's use skim to look at the new data frame


#how many people have been diagnosed with diabetes?


#what was the average age at diagnosis?


#how many people have pre-diabetes


#let's drop samples with a missing BMI


#how many samples do we have now?


```



